{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10E_R05OO1VSCiUwjg34_U9FPs2IubX7e",
      "authorship_tag": "ABX9TyMMCHRbEan/GC1CwzMUN8iu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Data/brainwaves.csv\")\n",
        "\n",
        "# Identify columns for each wave type(the dataset had multiple other types)\n",
        "delta_cols = [col for col in df.columns if \"delta\" in col.lower() and \"coh\" not in col.lower()]\n",
        "theta_cols = [col for col in df.columns if \"theta\" in col.lower() and \"coh\" not in col.lower()]\n",
        "alpha_cols = [col for col in df.columns if \"alpha\" in col.lower() and \"coh\" not in col.lower()]\n",
        "beta_cols = [col for col in df.columns if \"beta\" in col.lower() and \"highbeta\" not in col.lower() and \"coh\" not in col.lower()]\n",
        "gamma_cols = [col for col in df.columns if \"gamma\" in col.lower() and \"coh\" not in col.lower()]\n",
        "\n",
        "# Aggregate by mean across all electrodes for each wave type\n",
        "df[\"Delta\"] = df[delta_cols].mean(axis=1)\n",
        "df[\"Theta\"] = df[theta_cols].mean(axis=1)\n",
        "df[\"Alpha\"] = df[alpha_cols].mean(axis=1)\n",
        "df[\"Beta\"] = df[beta_cols].mean(axis=1)\n",
        "df[\"Gamma\"] = df[gamma_cols].mean(axis=1)\n",
        "\n",
        "# Keep only the five main brainwave categories\n",
        "df= df[[\"specific.disorder\", \"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]]\n",
        "\n",
        "print(df.head(3))\n",
        "\n",
        "# Save cleaned dataset\n",
        "df.to_csv(\"condensed_brainwave_data.csv\", index=False)\n",
        "\n",
        "print(\"Condensed dataset saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK0KsuXZ0Kpd",
        "outputId": "05cf91c4-ea3a-4b91-d884-5ff104020090"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         specific.disorder      Delta      Theta      Alpha       Beta  \\\n",
            "0  Social anxiety disorder  28.010640  19.579119  23.738571  13.549816   \n",
            "1      Depressive disorder  26.331350  18.540736  23.990099   9.906452   \n",
            "2      Depressive disorder  13.028539   8.629804  40.531323  16.568042   \n",
            "\n",
            "      Gamma  \n",
            "0  3.370627  \n",
            "1  2.484837  \n",
            "2  2.170563  \n",
            "Condensed dataset saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting  train/test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"condensed_brainwave_data.csv\")\n",
        "\n",
        "# Select features and target\n",
        "X = df[[\"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]]\n",
        "y = df[\"specific.disorder\"]\n",
        "\n",
        "# Check the distribution of the labels\n",
        "print(df[\"specific.disorder\"].value_counts())\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# After splitting into train and test sets\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OkrKAx03QFa",
        "outputId": "b29ad5e0-6289-4206-d905-fadd1b1e594c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "specific.disorder\n",
            "Depressive disorder        134\n",
            "Social anxiety disorder     43\n",
            "Adjustment disorder         33\n",
            "Healthy control             27\n",
            "Acute stress disorder        9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the MLP model\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(128, 64),  # Two hidden layers: 64 neurons â†’ 32 neurons\n",
        "                    activation='relu',           # ReLU activation for non-linearity\n",
        "                    solver='adam',               # Adam optimizer for adaptive learning\n",
        "                    alpha=0.0001,                 # L2 regularization to prevent overfitting\n",
        "                    batch_size=32,               # Mini-batch size\n",
        "                    max_iter=2000,                # Max training iterations\n",
        "                    random_state=42)\n",
        "\n",
        "# Now use X_train_resampled and y_train_resampled for training\n",
        "mlp.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(128, 64), (256, 128, 64)],\n",
        "    'alpha': [0.0001, 0.001],\n",
        "    'max_iter': [2000, 3000]\n",
        "}\n",
        "\n",
        "#grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy')\n",
        "#grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Print the best parameters found\n",
        "#print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "LFR31hg2AO9I"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}